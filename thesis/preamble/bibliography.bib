@article{Przybysz2013,
abstract = {These two quotations reflect common attitudes about music. Tolstoy's comment suggests that music conveys emotion, whereas Torke's question implies that music influences listeners' emotions. Section 5.2 of the present chapter includes a discussion of the various theoretical approaches that are used to explain affective responses to music. Few scholars dispute the claim that listeners recognize emotions in music. Some argue, however, that music does not elicit true emotions in the listener (e.g., Kivy 1980, 1990, 2001). For example, many years ago Meyer (1956) posited that affective responses to music consist of experiences of tension and relaxation (rather than actual emotions), which occur when listeners' expectancies about what will happen next in a piece of music are violated or fulfilled, respectively. This position has been challenged in recent years with findings from studies using behavioral, physiological, and neurological measures, all of which indicate that listeners respond affectively to music (e.g., Krumhansl 1997; Gagnon and Peretz 2003; Mitterschiffthaler et al. 2007; Witvliet and Vrana 2007). Nonetheless, the debate continues (e.g., Kone{\v{c}}ni 2008).},
author = {Przybysz, Piotr},
doi = {10.12849/40302013.1012.0011},
issn = {20826710},
journal = {Avant},
keywords = {Absolutist vs. referentialist views of musical meaning,Emotional response to music,Mmusic and emotion,Psychology of music,Stravinsky},
title = {{Music and emotions}},
year = {2013}
}

@misc{palaniappan2018,
title={{Spotify Product Analysis}},
url={https://medium.com/@vigneshp_/spotify-product-analysis-e76a59b5591},
journal={Medium},
publisher={Medium},
author={Palaniappan, Vignesh},
year={2018},
month={Jan}
}

@ONLINE{midiaresearch,
author={MIDiA-Research},
year={2019},
title={{About Us}},
url={https://www.midiaresearch.com/about-us/}
}

@inproceedings{Zhang2013,
abstract = {Spotify is a peer-assisted music streaming service that has gained worldwide popularity in the past few years. Until now, little has been published about user behavior in such services. In this paper, we study the user behavior in Spotify by analyzing a massive dataset collected between 2010 and 2011. Firstly, we investigate the system dynamics including session arrival patterns, playback arrival patterns, and daily variation of session length. Secondly, we analyze individual user behavior on both multiple and single devices. Our analysis reveals the favorite times of day for Spotify users. We also show the correlations between both the length and the downtime of successive user sessions on single devices. In particular, we conduct the first analysis of the device-switching behavior of a massive user base.},
author = {Zhang, Boxun and Kreitz, Gunnar and Isaksson, Marcus and Ubillos, Javier and Urdaneta, Guido and Pouwelse, Johan A. and Epema, Dick},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFCOM.2013.6566767},
isbn = {9781467359467},
issn = {0743166X},
title = {{Understanding user behavior in Spotify}},
year = {2013}
}

@article{Liikkanen2015,
abstract = {YouTube is the leading Internet video service and one of the most popular websites in 2014. Music videos hold top positions in different YouTube charts, but the music video types or engagement patterns with them have not been systematically studied. In this paper we present three studies that focus on YouTube music. We first show that music videos are the most popular content genre in YouTube. We then present a typology of traditional and user-generated music videos discovered in YouTube. It includes twelve subtypes of music videos under three main types: traditional, user-appropriated, and derivative. Last, we present findings on user engagement statistics that go beyond view, comment, and vote counts. These metrics show that while music videos gather more views, engagement differences with other content genres are miniscule. However, there are notable differences in engagement between different music video types. This is prominent between different artists on one hand, and between traditional and user-generated videos on the other. We synthesize these findings by discussing the importance of user-generated videos in YouTube's music ecosystem.},
author = {Liikkanen, Lassi A. and Salovaara, Antti},
doi = {10.1016/j.chb.2015.01.067},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Appropriation,Digital music,Music interaction,Music listening,YouTube},
title = {{Music on YouTube: User engagement with traditional, user-appropriated and derivative videos}},
year = {2015}
}

@misc{ifpi,
title={{IFPI releases 2018 Music Consumer Insight Report}},
url={https://www.ifpi.org/news/IFPI-releases-2018-music-consumer-insight-report},
journal={IFPI releases 2018 Music Consumer Insight Report},
year={2018},
month={Oct}
}

@misc{russell2018,
title={{China's NetEase raises \$600M for its music streaming business}},
url={https://techcrunch.com/2018/11/13/netease-cloud-music-raises-600-million/},
journal={TechCrunch},
publisher={TechCrunch},
author={Russell, Jon},
year={2018},
month={Nov}
}

@misc{mulligan2018,
author={Mulligan, Mark},
title={{Mid-Year 2018 Streaming Market Shares}},
year={2018},
url={https://www.midiaresearch.com/blog/mid-year-2018-streaming-market-shares/},
month={Sep}
}

@incollection{ricci2011introduction,
  title={Introduction to recommender systems handbook},
  author={Ricci, Francesco and Rokach, Lior and Shapira, Bracha},
  booktitle={Recommender systems handbook},
  pages={1--35},
  year={2011},
  publisher={Springer}
}

@book{Celma2010,
abstract = {In the last 15 years we have seen a major transformation in the world of music Musicians use inexpensive personal computers instead of expensive recording studios to record, mix and engineer music. Musicians use the Internet to distribute their music for free instead of spending large amounts of money creating CDs, hiring trucks and shipping them to hundreds of record stores. As the cost to create and distribute recorded music has dropped, the amount of available music has grown dramatically. Twenty years ago a typical record store would have music by less than ten thousand artists, while today online music stores have music catalogs by nearly a million artists. While the amount of new music has grown, some of the traditional ways of finding music have diminished. Thirty years ago, the local radio DJ was a music tastemaker, finding new and interesting music for the local radio audience. Now radio shows are programmed by large corporations that create playlists drawn from a limited pool of tracks Similarly, record stores have been replaced by big box retailers that have ever-shrinking music departments. In the past, you could always ask the owner of the record store for music recommendations. You would learn what was new, what was good and what was selling. Now, however, you can no longer expect that the teenager behind the cash register will be an expert in new music, or even be someone who listens to music at all. With so much more music available, listeners are increasingly relying on tools such as automatic music recommenders to help them find music. Instead of relying on DJs, record store clerks or their friends to get music recommendations, listeners are also turning to machines to guide them to new music. This raises a number of questions: How well do these recommenders work? Do they generate novel, interesting and relevant music recommendations? How far into the Long Tail do they reach? Do they create feedback loops that drive listeners to a diminishing pool of popular artists? What affect will automatic music recommenders have on the collective music taste? In this book, Dr Celma guides us through the world of automatic music recommendation. He describes how music recommenders work, explores some of the limitations seen in current recommenders, offers techniques for evaluating the effectiveness of music recommendations and demonstrates how to build effective recommenders by offering two real-world recommender examples. As we rely more and more on automatic music recommendation it is important for us to understand what makes a good music recommender and how a recommender can affect the world of music. With this knowledge we can build systems that offer novel, relevant and interesting music recommendations drawn from the entire world of available music. Paul Lamere, Director of Developer Community, The Echo Nest Austin, TX, March 2010},
author = {Celma, {\`{O}}scar},
booktitle = {Music Recommendation and Discovery},
doi = {10.1007/978-3-642-13287-2},
title = {{Music Recommendation and Discovery}},
year = {2010}
}

@misc{adjustedcosinesimilarity,
title={{Adjusted Cosine Similarity}}
url={http://www10.org/cdrom/papers/519/node14.html},
journal={Adjusted Cosine Similarity}
}

@article{joulin2016bag,
  title={Bag of tricks for efficient text classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}

@inproceedings{Brilis2012,
abstract = {This paper presents a case-study of the effectiveness of a trained system into classifying Greek songs according to their audio characteristics or/and their lyrics into moods. We examine how the usage of different algorithms, featureset combinations and pre-processing parameters affect the precision and recall percentages of the classification process for each mood model characteristic. Experimental results indicate that the current selection of features offers accuracy results, the superiority of lyrics content over generic audio features as well as potential caveats with current research in Greek language stemming pre-processing methods. {\textcopyright} 2012 IFIP International Federation for Information Processing.},
author = {Brilis, Spyros and Gkatzou, Evagelia and Koursoumis, Antonis and Talvis, Karolos and Kermanidis, Katia L. and Karydis, Ioannis},
booktitle = {IFIP Advances in Information and Communication Technology},
doi = {10.1007/978-3-642-33412-2_43},
isbn = {9783642334115},
issn = {18684238},
keywords = {Greek music,audio,lyrics,music mood classification},
title = {{Mood classification using lyrics and audio: A case-study in Greek music}},
year = {2012}
}

@article{DBLP:journals/corr/Raschka14,
  author    = {Sebastian Raschka},
  title     = {Naive Bayes and Text Classification {I} - Introduction and Theory},
  journal   = {CoRR},
  volume    = {abs/1410.5329},
  year      = {2014},
  url       = {http://arxiv.org/abs/1410.5329},
  archivePrefix = {arXiv},
  eprint    = {1410.5329},
  timestamp = {Mon, 13 Aug 2018 16:47:20 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Raschka14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{audio2018,
title={Metadata in Digital Audio Files – What it is, where it is and how to tidy it up.},
url={https://www.cambridgeaudio.com/usa/en/blog/metadata-digital-audio-files-–-what-it-where-it-and-how-tidy-it},
journal={Cambridge Audio},
year={2018},
month={Jan}
}

@article{kamenetsky1997effect,
  title={Effect of tempo and dynamics on the perception of emotion in music},
  author={Kamenetsky, Stuart B and Hill, David S and Trehub, Sandra E},
  journal={Psychology of Music},
  volume={25},
  number={2},
  pages={149--160},
  year={1997},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{bogdanov2013semantic,
  title={Semantic audio content-based music recommendation and visualization based on user preference examples},
  author={Bogdanov, Dmitry and Haro, Mart{\'\i}N and Fuhrmann, Ferdinand and Xamb{\'o}, Anna and G{\'o}mez, Emilia and Herrera, Perfecto},
  journal={Information Processing \& Management},
  volume={49},
  number={1},
  pages={13--33},
  year={2013},
  publisher={Elsevier}
}

@misc{euclidean,
title = {{'n'-dimensional euclidean distance}},
url={https://hlab.stanford.edu/brian/euclidean_distance_in.html},
journal={'n'-Dimensional Euclidean Distance}
}

@misc{craw1970,
title={Manhattan Distance},
url={https://link.springer.com/referenceworkentry/10.1007/978-0-387-30164-8_506},
journal={SpringerLink},
publisher={Springer, Boston, MA},
author={Craw, Susan},
year={1970},
month={Jan}
}

@misc{stephanie2018,
title={Mahalanobis Distance: Simple Definition, Examples},
url={https://www.statisticshowto.datasciencecentral.com/mahalanobis-distance/},
journal={Statistics How To},
author={Stephanie},
year={2018},
month={Aug}
}

@article{Su2009,
abstract = {As one of the most successful approaches to building recommender systems, collaborative filtering (CF) uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper, we first introduce CF tasks and their main challenges, such as data sparsity, scalability, synonymy, gray sheep, shilling attacks, privacy protection, etc., and their possible solutions. We then present three main categories of CF techniques: memory-based, model-based, and hybrid CF algorithms (that combine CF with other recommendation techniques), with examples for representative algorithms of each category, and analysis of their predictive performance and their ability to address the challenges. From basic techniques to the state-of-the-art, we attempt to present a comprehensive survey for CF techniques, which can be served as a roadmap for research and practice in this area.},
author = {Su, Xiaoyuan and Khoshgoftaar, Taghi M.},
doi = {10.1155/2009/421425},
issn = {1687-7470},
journal = {Advances in Artificial Intelligence},
title = {{A Survey of Collaborative Filtering Techniques}},
year = {2009}
}

@inproceedings{Bu2010,
abstract = {Acoustic-based music recommender systems have received increasing interest in recent years. Due to the semantic gap between low level acoustic features and high level music concepts, many researchers have explored collaborative filtering techniques in music recommender systems. Traditional collaborative filtering music recommendation methods only focus on user rating information. However, there are various kinds of social media information, including different types of objects and relations among these objects, in music social communities such as Last.fm and Pandora. This information is valuable for music recommendation. However, there are two challenges to exploit this rich social media information: (a) There are many different types of objects and relations in music social communities, which makes it difficult to develop a unified framework taking into account all objects and relations. (b) In these communities, some relations are much more sophisticated than pairwise relation, and thus cannot be simply modeled by a graph. In this paper, we propose a novel music recommendation algorithm by using both multiple kinds of social media information and music acoustic-based content. Instead of graph, we use hypergraph to model the various objects and relations, and consider music recommendation as a ranking problem on this hypergraph. While an edge of an ordinary graph connects only two objects, a hyperedge represents a set of objects. In this way, hypergraph can be naturally used to model high-order relations. Experiments on a data set collected from the music social community Last.fm have demonstrated the effectiveness of our proposed algorithm.},
author = {Bu, Jiajun and Tan, Shulong and Chen, Chun and Wang, Can and Wu, Hao and Zhang, Lijun and He, Xiaofei},
booktitle = {Proceedings of the 18th ACM international conference on Multimedia},
title = {{Music Recommendation by Unified Hypergraph: Combining Social Media Information and Music Content}},
year = {2010}
}

@misc{Kaminskas2012,
abstract = {Increasing amount of online music content has opened new opportunities for implementing new effective information access services-commonly known as music recommender systems-that support music navigation, discovery, sharing, and formation of user communities. In the recent years a new research area of contextual (or situational) music recommendation and retrieval has emerged. The basic idea is to retrieve and suggest music depending on the user's actual situation, for instance emotional state, or any other contextual conditions that might influence the user's perception of music. Despite the high potential of such idea, the development of real-world applications that retrieve or recommend music depending on the user's context is still in its early stages. This survey illustrates various tools and techniques that can be used for addressing the research challenges posed by context-aware music retrieval and recommendation. This survey covers a broad range of topics, starting from classical music information retrieval (MIR) and recommender system (RS) techniques, and then focusing on context-aware music applications as well as the newer trends of affective and social computing applied to the music domain. {\textcopyright} 2012 Elsevier Inc.},
author = {Kaminskas, Marius and Ricci, Francesco},
booktitle = {Computer Science Review},
doi = {10.1016/j.cosrev.2012.04.002},
issn = {15740137},
keywords = {Affective computing,Context-aware services,Music information retrieval,Music recommender systems,Social computing},
title = {{Contextual music information retrieval and recommendation: State of the art and challenges}},
year = {2012}
}

@article{Han2010,
abstract = {Context-based music recommendation is one of rapidly emerging applications in the advent of ubiquitous era and requires multidisciplinary efforts including low level feature extraction and music classification, human emotion description and prediction, ontology-based representation and recommendation, and the establishment of connections among them. In this paper, we contributed in three distinctive ways to take into account the idea of context awareness in the music recommendation field. Firstly, we propose a novel emotion state transition model (ESTM) to model human emotional states and their transitions by music. ESTM acts like a bridge between user situation information along with his/her emotion and low-level music features. With ESTM, we can recommend the most appropriate music to the user for transiting to the desired emotional state. Secondly, we present context-based music recommendation (COMUS) ontology for modeling user's musical preferences and context, and for supporting reasoning about the user's desired emotion and preferences. The COMUS is music-dedicated ontology in OWL constructed by incorporating domain-specific classes for music recommendation into the Music Ontology, which includes situation, mood, and musical features. Thirdly, for mapping low-level features to ESTM, we collected various high-dimensional music feature data and applied nonnegative matrix factorization (NMF) for their dimension reduction. We also used support vector machine (SVM) as emotional state transition classifier. We constructed a prototype music recommendation system based on these features and carried out various experiments to measure its performance. We report some of the experimental results.},
author = {Han, Byeong Jun and Rho, Seungmin and Jun, Sanghoon and Hwang, Eenjun},
doi = {10.1007/s11042-009-0332-6},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {Classification,Emotion,Emotion state transition model,Mood,Music information retrieval,Recommendation},
mendeley-groups = {comp},
title = {{Music emotion classification and context-based music recommendation}},
year = {2010}
}

@misc{pytextrank,
    author       = {ceteri},
    title        = {{Python impl for TextRank}},
    month        = Jun,
    year         = 2017,
    version      = {1.1.0},
    publisher    = {GitHub},
    url          = {https://github.com/DerwenAI/pytextrank}
    }

@article{Bertin-Mahieux2011,
abstract = {We introduce the Million Song Dataset, a freely-available collection of audio features and metadata for a million con- temporary popular music tracks. We describe its creation process, its content, and its possible uses. Attractive fea- tures of the Million Song Database include the range of ex- isting resources to which it is linked, and the fact that it is the largest current research dataset in our ﬁeld. As an illustra- tion, we present year prediction as an example application, a task that has, until now, been difﬁcult to study owing to the absence of a large set of suitable data. We show positive results on year prediction, and discuss more generally the future development of the dataset.},
author = {Bertin-Mahieux, Thierry and Ellis, Daniel P.W. and Whitman, Brian and Lamere, Paul},
doi = {10.1145/2187980.2188222},
isbn = {9781450312301},
issn = {1450312306},
journal = {Proceedings of the International Conferences on Music Information Retrieval (ISMIR'11)},
keywords = {music information retrieval,recommender systems},
title = {{The Million Song Dataset}},
year = {2011}
}

@ONLINE{ten,
title={The Echo Nest / Spotify APIs},
url={http://static.echonest.com/enspex/},
journal={The Echo Nest / Spotify APIs},
}

@ONLINE{webapi,
title={Get Audio Features for a Track},
url={https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/},
journal={Spotify for Developers},
}

@ONLINE{vue,
title={The Progressive JavaScript Framework},
url={https://vuejs.org/},
journal={Vue.js},
note="\url{https://vuejs.org/}"
}

@ONLINE{django,
title={Django makes it easier to build better Web apps more quickly and with less code.},
url={https://www.djangoproject.com/},
journal={django},
note="\url{https://www.djangoproject.com/}"
}
